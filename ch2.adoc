= Chapter 2: Kubernetes basics 
:toc: manual
:toc-placement: preamble
:source-highlighter: pygments
:source-highlighter: coderay
:source-highlighter: prettify
:highlightjs-theme: googlecode
:coderay-linenums-mode: table
:coderay-linenums-mode: inline

This chapter introduces kubernetes, what is it, the basic terminologies and key
concepts of it. You will learn most of the commonly used and mentioned
components in kubernetes architecture. This chapter also provides an example to
launch a "minimal", but relatively complete kubernetes environment to
demonstrate how to interact with kubernetes in practice and how the virtual
environment orchestrated by kubernetes looks like.

== What is Kubernetes 

This is the description from the main page of official kubernetes website
(https://kubernetes.io/) :

____
Kubernetes (K8s) is an open-source system for automating deployment, scaling,
and management of containerized applications. It groups containers that make up
an application into logical units for easy management and discovery. Kubernetes
builds upon 15 years of experience of running production workloads at Google,
combined with best-of-breed ideas and practices from the community.
____

this brief description tells a few important facts about kubernetes:

* initiated by google but open-sourced now
* mature and stable product after many years effort
* orchestration tool
* dealing with containers in a higher level

////
> Kubernetes is a portable, extensible open-source platform for managing
> containerized workloads and services, that facilitates both declarative
> configuration and automation. 

> Google open-sourced the Kubernetes project in 2014. Kubernetes builds upon a
> decade and a half of experience that Google has with running production
> workloads at scale, combined with best-of-breed ideas and practices from the
> community.
////

kubernetes was created by a group of engineers in google in 2014, with a design
and development model influenced by Google's internal system named "Borg" .
Kubernetes defines a set of "building objects" (e.g. "pod", "service") which
collectively provides mechanisms that orchestrates containerized applications
across a distributed cluster of nodes, based on system resources (CPU, memory
or other custom metrics).  Kubernetes hides the complexity of managing a group
of containers by providing REST APIs for the required functionalities. 

In simple words, container technologies like docker provides you the capability
of packaging and distributing containerized applications, while an
orchestration system like kubernetes allows you to deploy and manage the
dockers in a relatively higher level and a much easier way.

[TIP]
====
* "Borg" is still being used in google internally today
* in many document kubernetes is frequently abbreviated as "k8s" (K - eight
  characters - S), 
* the "current" (as of the writing of this book) major release is v1.14.
====

== Kubernetes Architecture and components

in a Kubernetes cluster there are two type of nodes, each running a very
well-defined set of processes:

* head node: called "master", or "master node", your head and brian that does
  all thinking and decisions, all of intelligence are located here.
* worker node: called "node", or "union" in old document, your arms and feet
  that conduct the workforce.

NOTE: the term "node" may sound semantically ambiguous - it could mean two
things in the context of this book. Usually a "node" refers to a logical unit
in a cluster - something we call a "server", which can be either physical
server (.e.g.: HP server) or virtual machine(e.g.: kvm-qemu based). in context
of kubernetes clusters, a "node" specifically refers to a "worker node" that
runs containerized applications, in contrast with a "master".

=== Kubernetes "master"

A kubernetes "master node", or "master", is like one's head and brian. in the
cluster master provides the "control plane" that makes all of the global
decisions about the cluster. for example, when you need the cluster to spawn a
container, the master will decide which node to dispatch the task and spawn a
container. this procedure is called "scheduling". master is also responsible
for maintaining the desired state for the cluster. when you give an order "for
this web server make sure there are always 2 containers backing up each
other!", the master will keep monitor the running status and starting up a
container anytime when it sees the number of the web server containers in
"running" status is less than 2. The master is also responsible for other many
jobs. Typically you only need a single master node in the cluster, however, the
master can also be replicated for higher availability (HA) and redundancy.

the master's functions is implemented by a collection of processes running in
node.  The processes in a master node providing the primary features are:
////
and detecting and responding to cluster
events ().
////

* *kube-apiserver*: front-end of the control plane, providing REST APIs
* *kube-scheduler*: do the "scheduling": decide where to place the containers
  depending on system requirement (CPU, memory, harddisk, etc) and other custom
  parameters or constraints (e.g. affinity specification)
* *kube-controller-manager*: the single process implementing most of the
  different type of "controllers", which makes sure that the state of the
  system is what it should be. TODO

  - RC(Replication Controller)
  - RS(ReplicaSet)
  - Deployment
  - StatefulSet
  - DS(DaemonSet)
  - Job
  - Node Controller
  - Service Controller

* *cloud-controller-manager*: TODO
* *etcd*: data store to store the state of the system. 
* *DNS server* for Kubernetes services. 
* *kubelet*: TODO

////
* And sometimes, to be able to manage all of this you have a
  process called a Kubelet. 
* And, of course, you have a container engine, you have Docker. You could have
* something else, but most of the time you have
* Docker. That's what you find on the head node, the brain of Kubernetes.
* Nothing else than four types of processes, an API server, a scheduler, a
* controller manager, and etcd. 
////

One of the most common interface between you and the cluster is a command-line
tool "kubectl". just remember: When you are working with "kubectl" command
later on, you're essentially communicating with the cluster's "master".

=== Kubernetes "node"

nodes in a cluster are the machines that run the final applications. in
production there can be dozens or hundreds of nodes in one cluster depending on
the designed scales. nodes are the real workforce under the hood provided by a
cluter. All of the containers and workloads are running in nodes. The "nodes"
are controlled by the "master" which you will interact with most of the time.
youâ€™ll rarely need to "bypass" the master and work with nodes directly.

A "node" runs following processes:

* *Kubelet*: the Kubernetes agent process that runs on all the nodes. it
  interacts with master (through kube-apiserver process) and manage the
  containers in local host.
* *kube-proxy*: process that implements "kubernetes service" (will introduce
  later) using linux iptable in the node
* *container-runtime*: local container - mostly 'docker' in today's market,
  holding all of the running "dockerized" applications.

TIP: the name "proxy" may sound confusing for kubernetes beginners. it's not
really a "proxy" in current kubernetes architecture. kube-proxy is a system
that manipulates linux IP tables in that node so that the the traffic between
the pods and the nodes will flows correctly.

=== kubernetes cluster lab environment

after you get some basic idea about the master and node and the main processes
running in each, it is the good time to look at how things works together in a
diagram.

TODO: pick one or make a new one.

image::https://user-images.githubusercontent.com/2038044/45911926-b5345180-bde7-11e8-82bd-152fffa2774a.png[]
//image::https://user-images.githubusercontent.com/2038044/46121001-c7473300-c1df-11e8-90c0-425b94957df1.png[]

image::https://user-images.githubusercontent.com/2038044/56502199-89915b00-64df-11e9-98a9-8ec5a786fff7.png[]

At the top is where you are. kubernetes "master" is in the middle and the
bottom 3 boxes are the "node".  The "standard" (most commonly used) interface
between you and the kubernetes master, or also the whole cluster, is a command
line application named `kuberctl`. It is installed as a client application
either in the same "master" node or in a seperate machine like your PC.
regardless of where it is, it interacts with the master process
"kube-apiserver" via its REST-API exposed to the user and other processes in
the system.

Now let's say you send some kubectl commands - something like `kubectl create
x`, to spawn a new container. You can give details about how exactly you want
your container to be spawned along with the running behaviors. the container
specifications can be provided either as kubectl command line parameters, or
options and values defined in a config file. You will read more on this in
later sections.

The kubectl client will first translate your task to one more REST-API call(s)
sent to "kube-apiserver". After the REST-API is validated, "kube-apiserver"
understands the task and will call "kube-scheduler" process to select a "worker
node", or a "node" in kubernetes term, from all 3 available worker nodes to
start the job. this is the scheduling procedure.

Once the "target node" is determined, "kube-apiserver" will dispatch the task
to the target node with all of the details describing the task. "kubelet"
process in the target node receives the task and talk to the final container
engine, for example the "docker engine" in this diagram, to spawn a container
with all provided parameters.

This job and its specification will be recorded in a centralized database
`etcd`. its job is to preserve and provide access to all data of the cluster. 

This is just a very simplified work flow to give you the basic idea. In fact
with the power of kubernetes you rarely need to work with containers directly.
you will work with some higher level objects which, hide most of the low level
operation and details and present the task in a higher level and much simpler
form. 

for example, in this diagram when you give the task to spawn containers,
instead of saying "create two containers and make sure to immediately spawn a
new one if either one would fail", you just say "create a RC ('replica
controller') with replica two". what will happen now is that once the 2 docker
containers are up and running, kube-apiserver will interact with
'kube-controller-manager' to keep monitoring the job status, and take necessary
actions to make sure the running status is what it was defined. for example you
will observe that if any one of two docker containers goes down, a third
container will be spawned and the broken one will be removed automatically.

the 'RC' in this example, is one of the "objects" that is provided by
kubernetes. The kubernetes objects provide an extra layer of abstraction that
gets the same (and usually more) work done under the hood, in a simpler and
clean way. Furthermore, because you are working in a higher level and staying
away from the low level details, kubernetes sharply reduces your overall
deployment time, brain effort, and troubleshooting pains.

The small "cost" of working in a level higher than docker engine is to
understand a few extra "kubernetes objects". 

you will read more about kubernetes objects in the next section.

////
Accordingly, after getting the REST-API, kube-apiserver will communicate with
the "controller-manager" to conduct the task and dispatch to the target node. 
////

=== kubernetes objects 

==== high level abstractions: docker vs kubernetes

Now you understand the role of 'master' and 'node' in a kubernetes cluster, and
in a diagram you see how a basic workflow looks. now let's start to look at
more kubernetes "objects" in the kubernetes architecture.

as mentioned earlier, technically speaking, kubernetes works in a relatively
higher level than dockers. what does that mean exactly? One analogy is to
compare python with c language. with python most often you only think of which
existing module already provides the magic you need, and once you imort that
module in your application, your focus will be how to use the feature to get
your things done. you rarely need to worry about the low-level system API calls
and hardware details.

//with assembly you will need to deal with register, flags, memory address, CPU
//vendor, model and all of the hardward specific low level details.

another good one will be TCP/IP Internet protocols. when you decide to rewrite
the FTP, you will prefer using TCP socket instead of raw socket. The TCP socket
provides a much more solid fundation that has all of the built-in reliability
features like error detection, flow and congestion control, retransmission and
so on. what you need to consider is only how do you deliver the data from one
end and receive the data from the other end. with raw socket you are working on
IP layer, so you have to consider and implement all of the reliability features
before your FTP application can be used in production.

back to our topic, Assuming you want to run multiple containers across multiple
machines, you will have a lot of work to do if you interact with docker
directly. at least the following tasks should be in your "worry list":

////
* start the right containers at the right time
* figure out how they can talk to each other
* consider storage configuration
* deal with failed containers or hardware
* consider to add redundancies and high availability to your docker application
////

* login different machines and Spawning containers across the network
* Scaling up or down by adding or removing containers when demand changes
* Keeping storage consistent with multiple instances of an application
* Distributing load between the containers running in different node
* Launching new containers on different machines if something fails

you will quickly find that doing all of this manually with docker will be
overwhelming. with the high-level abstractions and the objects representing
them in kubernetes API, all of these tasks become much easiler. 


==== kubernetes object

Kubernetes's objects represent the state of the system: 
* deployed containerized applications and workloads
* their associated network and disk resources
* other information about what the cluster is doing. 

there are different type of objects:
* basic Kubernetes objects
    - Pod
    - Service
    - Volume
    - Namespace
* higher-level abstractions (Controllers): build upon the basic objects, and
  provide additional functionality and convenience features. 

    - ReplicaSet
    - Deployment
    - StatefulSet
    - DaemonSet
    - Job

here is a diagram showing relationships between the terms: "feature",
"abstraction", "objects", process and controller

                +---------------------------------------+
    features    |                                       |
        |       |                                       |
        |       +---------------------------------------+
        |       | high level objects: RC,RS,DE,SS,DS,JOB|
        v       |   (controller process)  |             |
    abstractions| ........................|...........  |
    (objects)   |                         v             |
        |       | basic objects: POD,SERVICE,VOLUME,NS  |
        |       +---------------------------------------+
        v       |                                       |
    containers  |     docker engine                     |
                +---------------------------------------+

in the frontend, kubernetes get all these things done via a group of
abstractions, each represented in the form of an "object". with kubernetes you
only needs to think of how to describe your task in the config file, without
the need to worry about how it will be implemented.

"under the hood", kubernetes interact with the Docker engine to coordinate the
scheduling and execution of Docker containers on Kubelets. The Docker engine
itself is responsible for running the actual container image (e.g. by 'docker
build'). 

Higher level concepts such as service-discovery, loadbalancing and
network policies are handled by Kubernetes as well.

later you will see real examples to understand the power of kubernetes objects.

////
The following steps explore how to build a kubernetes "RC" object: replica
conroller - one of the popular kubernetes objects. more objects will be
introduced in later chapters. the simple two steps are as following:

. create a yaml file: myweb_rc.yaml
+
```yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: myweb
spec:
  replicas: 2
  selector:
    app: myweb
  template:
    metadata:
      labels:
        app: myweb
    spec:
      containers:
      - name: myweb
        image: kubeguide/tomcat-app:v1
        ports:
        - containerPort: 8080
```

. create the objects based on the yaml file
+
```bash
kubectl create -f myweb_rc.yaml
replicationcontroller/myweb created
```

first you create a `yaml` file to describe the object you want kubernetes to
create for you. `yaml` is a popular format to describe data structure and it is
used by kubernetes to define all its objects.
In the file is all parameters of the objects that will be spawned by
kubernetes. 
here in this example:
* the object type is "ReplicationController" - the RC
* object name is "myweb"
* replicas - the number of pod that will be launched by the RC is 2.
* 



to list the created objects:

```bash

$ kubectl get rc
NAME      DESIRED   CURRENT   READY     AGE
mysql     1         1         0         10s         #<------
myweb     2         2         2         10s


$ kubectl get pod
NAME          READY     STATUS              RESTARTS   AGE
myweb-nv4h8   1/1       ContainerCreating   1          1m       #<---
myweb-vzvk4   1/1       Running             1          1m
```

```bash
root@test1:~# kubectl get pod -o wide
NAME          READY     STATUS    RESTARTS   AGE       IP                NODE      NOMINATED NODE
myweb-lk8jb   1/1       Running   0          1m        192.168.231.209   test3     <none>
myweb-shtj4   1/1       Running   0          1m        192.168.215.19    test2     <none>
```
////

=== Kubernetes networking

.PLAN: 
*ip-per-pod model
*give brief introduction only

=== a "full picture" - put everything together

.PLAN
a diagram to show most of the components and concepts


== Building Kubernetes POD

first kubernetes object
short introduction

=== YAML file for Kubernetes 

==== yaml basis

.data structures
* scalars (strings/numbers): atom data item
* sequences (arrays/lists): collection of ordered values, without keys.
* mappings (hashes/dictionaries): key-value pairs

.rules:
* case sensitive
* elements in same level share same left indentation
* indentation amount does not matter
* not allow tab characters to be used for indentation
* blank lines does not matter
* comment by "#"
* use quote "'" to escape special meaning of any chars

==== POD example using YAML files

    $ cat frontend-localredis-pod.yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: redis-php
      labels:
          name: redis-php
    spec:
      containers:
      - name: frontend
        image: kubeguide/guestbook-php-frontend:localredis
        ports:
        - containerPort: 80
      - name: redis
        image: kubeguide/redis-master
        ports:
        - containerPort: 6379

    $ kubectl create -f frontend-localredis-pod.yaml
    pod/redis-php created

    root@test1:~# kubectl get pod
    NAME        READY     STATUS              RESTARTS   AGE
    redis-php   0/2       ContainerCreating   0          13s

    root@test1:~# kubectl get pod -o wide
    NAME        READY     STATUS              RESTARTS   AGE       IP        NODE      NOMINATED NODE
    redis-php   0/2       ContainerCreating   0          15s       <none>    test2     <none>

    root@test1:~# kubectl get pod -o wide
    NAME        READY     STATUS    RESTARTS   AGE       IP              NODE      NOMINATED NODE
    redis-php   2/2       Running   0          27s       192.168.215.1   test2     <none>

=== Kubectl tool 

=== Login to container 

=== Intra-POD communications  

=== Inter-POD communications
